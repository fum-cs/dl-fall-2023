{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJtKN6ANUADM"
      },
      "source": [
        "# GFPGAN Inference Demo\n",
        "\n",
        "https://github.com/TencentARC/GFPGAN\n",
        "\n",
        "### (No colorization; No CUDA extensions required)\n",
        "\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2101.04061)\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/TencentARC/GFPGAN?style=social)](https://github.com/TencentARC/GFPGAN)\n",
        "[![download](https://img.shields.io/github/downloads/TencentARC/GFPGAN/total.svg)](https://github.com/TencentARC/GFPGAN/releases)\n",
        "\n",
        "## GFPGAN - Towards Real-World Blind Face Restoration with Generative Facial Prior\n",
        "\n",
        "GFPGAN is a blind face restoration algorithm towards real-world face images. <br>\n",
        "It leverages the generative face prior in a pre-trained GAN (*e.g.*, StyleGAN2) to restore realistic faces while precerving fidelity. <br>\n",
        "\n",
        "If you want to use the paper model, please go to this [Colab Demo](https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing) for GFPGAN <a href=\"https://colab.research.google.com/drive/1Oa1WwKB4M4l1GmR7CtswDVgOCOeSLChA?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"google colab logo\"></a>.\n",
        "\n",
        "**Limitations**: GFPGAN could not handle all the low-quality faces in the real world. Therefore, it may fail on your own cases.\n",
        "\n",
        "###Enjoy! :-)\n",
        "\n",
        "<img src=\"https://xinntao.github.io/projects/GFPGAN_src/gfpgan_teaser.jpg\" width=\"800\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY1Zbo3uUkXg"
      },
      "source": [
        "# 1. Preparations\n",
        "Before start, make sure that you choose\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU\n",
        "\n",
        "in the **Runtime** menu -> **Change runtime type**\n",
        "\n",
        "Then, we clone the repository, set up the envrironment, and download the pre-trained model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwH2ifWEYEfJ",
        "outputId": "a558184c-a53c-44ee-8284-f2c5d29187e8"
      },
      "outputs": [],
      "source": [
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN\n",
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "%cd GFPGAN\n",
        "\n",
        "# Set up the environment\n",
        "# Install basicsr - https://github.com/xinntao/BasicSR\n",
        "# We use BasicSR for both training and inference\n",
        "!pip install basicsr\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "# Install other depencencies\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions\n",
        "# Download the pre-trained model\n",
        "# !wget https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth -P experiments/pretrained_models\n",
        "# Now we use the V1.3 model for the demo\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-8JxpPwg4Xz"
      },
      "source": [
        "# 2. Upload Images / Use the demo images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "CdMZYp0T7NAy",
        "outputId": "60fa96b8-76e1-4666-ed61-314ed5c7222f"
      },
      "outputs": [],
      "source": [
        "# # upload your own images\n",
        "# import os\n",
        "# from google.colab import files\n",
        "# import shutil\n",
        "\n",
        "# upload_folder = 'inputs/upload'\n",
        "\n",
        "# if os.path.isdir(upload_folder):\n",
        "#     shutil.rmtree(upload_folder)\n",
        "# os.mkdir(upload_folder)\n",
        "\n",
        "# # upload images\n",
        "# uploaded = files.upload()\n",
        "# for filename in uploaded.keys():\n",
        "#   dst_path = os.path.join(upload_folder, filename)\n",
        "#   print(f'move {filename} to {dst_path}')\n",
        "#   shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dZUYDlMeXKe"
      },
      "source": [
        "### Using our images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d6CkQ2x-eSjH",
        "outputId": "cc1d0b8b-5f99-448c-b445-1cea96e7f288"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'inputs/upload/Blake_Lively.jpg'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "upload_folder = 'inputs/upload'\n",
        "\n",
        "!git clone https://github.com/fum-cs/dl.git\n",
        "src = 'dl/code/images'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.makedirs(upload_folder, exist_ok=True)\n",
        "for file in os.listdir (src):\n",
        "    shutil.copy2(os.path.join (src, file), upload_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Python program to explain shutil.copytree() method \n",
        "\t\n",
        "# importing os module \n",
        "import os \n",
        "\n",
        "# importing shutil module \n",
        "import shutil \n",
        "\n",
        "# path \n",
        "# path = 'C:/Users / hp / Desktop / GeeksforGeeks'\n",
        "\n",
        "# # List files and directories \n",
        "# # in 'C:/Users / Rajnish / Desktop / GeeksforGeeks' \n",
        "# print(\"Before copying file:\") \n",
        "# print(os.listdir(path)) \n",
        "\n",
        "\n",
        "# Source path \n",
        "src = 'C:/Users/hp/p1'\n",
        "\n",
        "# Destination path \n",
        "dst = 'C:/Users/hp/p2'\n",
        "\n",
        "# Copy the content of \n",
        "# source to destination \n",
        "# destination = shutil.copytree(src, dest) \n",
        "\n",
        "for file in os.listdir (src):\n",
        "    shutil.copy2 (os.path.join (src, file), dst)\n",
        "\n",
        "# List files and directories \n",
        "# in \"C:/Users / Rajnish / Desktop / GeeksforGeeks\" \n",
        "# print(\"After copying file:\") \n",
        "# print(os.listdir(path)) \n",
        "\n",
        "# # Print path of newly \n",
        "# # created file \n",
        "# print(\"Destination path:\", destination) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGHc73Up70ZA"
      },
      "source": [
        "## 3. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmQVC3s97z4z",
        "outputId": "1ad75447-60de-4004-ca21-df456d756bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            "/content/GFPGAN/inference_gfpgan.py:63: UserWarning: The unoptimized RealESRGAN is slow on CPU. We do not use it. If you really want to use it, please modify the corresponding codes.\n",
            "  warnings.warn('The unoptimized RealESRGAN is slow on CPU. We do not use it. '\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.1.0/detection_Resnet50_Final.pth\" to /content/GFPGAN/gfpgan/weights/detection_Resnet50_Final.pth\n",
            "\n",
            "100% 104M/104M [00:00<00:00, 177MB/s]\n",
            "Downloading: \"https://github.com/xinntao/facexlib/releases/download/v0.2.2/parsing_parsenet.pth\" to /content/GFPGAN/gfpgan/weights/parsing_parsenet.pth\n",
            "\n",
            "100% 81.4M/81.4M [00:00<00:00, 164MB/s]\n",
            "Processing 1399101110160626521916244.jpg ...\n",
            "Processing QasemSoleimani.jpg ...\n",
            "Processing mAmintoosi_1400.jpg ...\n",
            "Results are in the [results] folder.\n",
            "1399101110160626521916244_00.png  mAmintoosi_1400_00.png  QasemSoleimani_00.png\n"
          ]
        }
      ],
      "source": [
        "# Now we use the GFPGAN to restore the above low-quality images\n",
        "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
        "# You can find the different models in https://github.com/TencentARC/GFPGAN#european_castle-model-zoo\n",
        "!rm -rf results\n",
        "!python inference_gfpgan.py -i inputs/upload -o results -v 1.3 -s 2 --bg_upsampler realesrgan\n",
        "\n",
        "# Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...\n",
        "#\n",
        "#  -h                   show this help\n",
        "#  -i input             Input image or folder. Default: inputs/whole_imgs\n",
        "#  -o output            Output folder. Default: results\n",
        "#  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3\n",
        "#  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "#  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "#  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "#  -suffix              Suffix of the restored faces\n",
        "#  -only_center_face    Only restore the center face\n",
        "#  -aligned             Input are aligned faces\n",
        "#  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto\n",
        "\n",
        "!ls results/cmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkF8VAiF7-PY"
      },
      "source": [
        "## 4. Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tIeL_NJO8A3B",
        "outputId": "c18f262c-d48b-4c3e-b3b3-888c9a73873f"
      },
      "outputs": [],
      "source": [
        "# We first visualize the cropped faces\n",
        "# The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('GFPGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'results/cropped_faces'\n",
        "result_folder = 'results/restored_faces'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "Jn_2ylqP9qXY",
        "outputId": "7107e49b-7738-4184-d3f6-36ce41092bbb"
      },
      "outputs": [],
      "source": [
        "# We then visualize the whole image\n",
        "# The left are the inputs images; the right are the results of GFPGAN\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input image', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('GFPGAN output', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "# display each image in the upload folder\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/upload'\n",
        "result_folder = 'results/restored_imgs'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR7VEBEb8slX"
      },
      "source": [
        "## 5. Download results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zuBCgeH08tdn",
        "outputId": "9f1479b0-83f5-4586-90c6-81e393c37212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cmp  cropped_faces  restored_faces  restored_imgs\n",
            "Download results\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_71e87d30-1ef6-4269-b3da-7425705733a6\", \"download.zip\", 4014164)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# download the result\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system('zip -r download.zip results')\n",
        "files.download(\"download.zip\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RJtKN6ANUADM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
