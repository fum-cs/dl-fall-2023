{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "M. Amintoosi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "تفاوت Tensor و Variable:\n",
    "\n",
    "1. tf.Variable: یک متغیر قابل تغییر است که مقدار آن در طول زمان در مدل TensorFlow قابل تغییر است. متغیرها در TensorFlow می‌توانند مقدار داشته باشند که در حین آموزش تغییر می‌کند. می‌توانند با استفاده از عملگرهایی مانند افزایش و کاهش مقدار، به روزرسانی شوند. معمولاً tf.Variable برای نگهداری وزن‌ها و بایاس‌ها در شبکه‌های عصبی استفاده می‌شود.\n",
    "\n",
    "2. tf.Tensor: نمایش‌دهنده یک جریان داده است که در ساختارهای داده چند بعدی به کار می‌رود. tf.Tensor مقادیر تنسور را در خود نگه‌داری می‌کند و تبدیل‌های ریاضی و منطقی روی آنها اعمال می‌کند. معمولاً tf.Tensor نتیجه‌ی تحلیل یا محاسباتی در TensorFlow است که به عنوان ورودی یا خروجی به لایه‌ها و عملگرها مورد استفاده قرار می‌گیرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto gradient using Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.0>\n",
      "tf.Tensor(3.0, shape=(), dtype=float32) tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(0.0)\n",
    "print(x)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "print(y, grad_of_y_wrt_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto gradient using Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(2.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(0.0)\n",
    "print(x)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = 2 * x + 3\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "print(x,grad_of_y_wrt_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تبدیل مقادیر عددی معمولی  به تنسور"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=-3.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.5>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 3.0\n",
    "o = -x\n",
    "w = 0.5\n",
    "x, o, w = [tf.convert_to_tensor(float(a)) for a in [x, o, w]]\n",
    "x, o, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الگوریتم گرادیان کاهشی با تنسورها"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 20.25,  w = 00.23 \n",
      "Loss = 13.62,  w = 00.01 \n",
      "Loss = 09.16,  w = -0.17 \n",
      "Loss = 06.16,  w = -0.32 \n",
      "Loss = 04.14,  w = -0.44 \n",
      "Loss = 02.78,  w = -0.54 \n",
      "Loss = 01.87,  w = -0.63 \n",
      "Loss = 01.26,  w = -0.69 \n",
      "Loss = 00.85,  w = -0.75 \n",
      "Loss = 00.57,  w = -0.79 \n",
      "Loss = 00.38,  w = -0.83 \n",
      "Loss = 00.26,  w = -0.86 \n",
      "Loss = 00.17,  w = -0.89 \n",
      "Loss = 00.12,  w = -0.91 \n",
      "Loss = 00.08,  w = -0.92 \n",
      "Loss = 00.05,  w = -0.94 \n",
      "Loss = 00.04,  w = -0.95 \n",
      "Loss = 00.02,  w = -0.96 \n",
      "Loss = 00.02,  w = -0.97 \n",
      "Loss = 00.01,  w = -0.97 \n"
     ]
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(3.0)\n",
    "w = tf.convert_to_tensor(0.5)\n",
    "o = tf.convert_to_tensor(-3.0)\n",
    "for _ in range(20):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(w)\n",
    "        loss = (o - w * x) ** 2\n",
    "    grad_loss = tape.gradient(loss, w)\n",
    "    w -= 0.01 * grad_loss\n",
    "    print(\"Loss = {:05.2f},  w = {:05.2f} \".format(loss.numpy(), w.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مشتق‌گیری برحسب ایکس به جای دبلیو"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 20.25,  x = 02.55 \n",
      "Loss = 18.28,  x = 02.12 \n",
      "Loss = 16.49,  x = 01.72 \n",
      "Loss = 14.89,  x = 01.33 \n",
      "Loss = 13.43,  x = 00.96 \n",
      "Loss = 12.12,  x = 00.62 \n",
      "Loss = 10.94,  x = 00.29 \n",
      "Loss = 09.88,  x = -0.03 \n",
      "Loss = 08.91,  x = -0.33 \n",
      "Loss = 08.04,  x = -0.61 \n",
      "Loss = 07.26,  x = -0.88 \n",
      "Loss = 06.55,  x = -1.14 \n",
      "Loss = 05.91,  x = -1.38 \n",
      "Loss = 05.34,  x = -1.61 \n",
      "Loss = 04.82,  x = -1.83 \n",
      "Loss = 04.35,  x = -2.04 \n",
      "Loss = 03.92,  x = -2.24 \n",
      "Loss = 03.54,  x = -2.43 \n",
      "Loss = 03.20,  x = -2.60 \n",
      "Loss = 02.88,  x = -2.77 \n",
      "Loss = 02.60,  x = -2.93 \n",
      "Loss = 02.35,  x = -3.09 \n",
      "Loss = 02.12,  x = -3.23 \n",
      "Loss = 01.91,  x = -3.37 \n",
      "Loss = 01.73,  x = -3.50 \n",
      "Loss = 01.56,  x = -3.63 \n",
      "Loss = 01.41,  x = -3.75 \n",
      "Loss = 01.27,  x = -3.86 \n",
      "Loss = 01.15,  x = -3.97 \n",
      "Loss = 01.03,  x = -4.07 \n",
      "Loss = 00.93,  x = -4.16 \n",
      "Loss = 00.84,  x = -4.26 \n",
      "Loss = 00.76,  x = -4.34 \n",
      "Loss = 00.69,  x = -4.43 \n",
      "Loss = 00.62,  x = -4.51 \n",
      "Loss = 00.56,  x = -4.58 \n",
      "Loss = 00.50,  x = -4.65 \n",
      "Loss = 00.45,  x = -4.72 \n",
      "Loss = 00.41,  x = -4.78 \n",
      "Loss = 00.37,  x = -4.84 \n",
      "Loss = 00.33,  x = -4.90 \n",
      "Loss = 00.30,  x = -4.96 \n",
      "Loss = 00.27,  x = -5.01 \n",
      "Loss = 00.25,  x = -5.06 \n",
      "Loss = 00.22,  x = -5.11 \n",
      "Loss = 00.20,  x = -5.15 \n",
      "Loss = 00.18,  x = -5.19 \n",
      "Loss = 00.16,  x = -5.23 \n",
      "Loss = 00.15,  x = -5.27 \n",
      "Loss = 00.13,  x = -5.31 \n",
      "Loss = 00.12,  x = -5.34 \n",
      "Loss = 00.11,  x = -5.38 \n",
      "Loss = 00.10,  x = -5.41 \n",
      "Loss = 00.09,  x = -5.44 \n",
      "Loss = 00.08,  x = -5.46 \n",
      "Loss = 00.07,  x = -5.49 \n",
      "Loss = 00.06,  x = -5.52 \n",
      "Loss = 00.06,  x = -5.54 \n",
      "Loss = 00.05,  x = -5.56 \n",
      "Loss = 00.05,  x = -5.59 \n",
      "Loss = 00.04,  x = -5.61 \n",
      "Loss = 00.04,  x = -5.63 \n",
      "Loss = 00.04,  x = -5.64 \n",
      "Loss = 00.03,  x = -5.66 \n",
      "Loss = 00.03,  x = -5.68 \n",
      "Loss = 00.03,  x = -5.70 \n",
      "Loss = 00.02,  x = -5.71 \n",
      "Loss = 00.02,  x = -5.72 \n",
      "Loss = 00.02,  x = -5.74 \n",
      "Loss = 00.02,  x = -5.75 \n",
      "Loss = 00.02,  x = -5.76 \n",
      "Loss = 00.01,  x = -5.78 \n",
      "Loss = 00.01,  x = -5.79 \n",
      "Loss = 00.01,  x = -5.80 \n",
      "Loss = 00.01,  x = -5.81 \n",
      "Loss = 00.01,  x = -5.82 \n",
      "Loss = 00.01,  x = -5.83 \n",
      "Loss = 00.01,  x = -5.84 \n",
      "Loss = 00.01,  x = -5.84 \n",
      "Loss = 00.01,  x = -5.85 \n",
      "Loss = 00.01,  x = -5.86 \n",
      "Loss = 00.00,  x = -5.87 \n",
      "Loss = 00.00,  x = -5.87 \n",
      "Loss = 00.00,  x = -5.88 \n",
      "Loss = 00.00,  x = -5.88 \n",
      "Loss = 00.00,  x = -5.89 \n",
      "Loss = 00.00,  x = -5.90 \n",
      "Loss = 00.00,  x = -5.90 \n",
      "Loss = 00.00,  x = -5.91 \n",
      "Loss = 00.00,  x = -5.91 \n",
      "Loss = 00.00,  x = -5.92 \n",
      "Loss = 00.00,  x = -5.92 \n",
      "Loss = 00.00,  x = -5.92 \n",
      "Loss = 00.00,  x = -5.93 \n",
      "Loss = 00.00,  x = -5.93 \n",
      "Loss = 00.00,  x = -5.93 \n",
      "Loss = 00.00,  x = -5.94 \n",
      "Loss = 00.00,  x = -5.94 \n",
      "Loss = 00.00,  x = -5.94 \n",
      "Loss = 00.00,  x = -5.95 \n"
     ]
    }
   ],
   "source": [
    "x = tf.convert_to_tensor(3.0)\n",
    "w = tf.convert_to_tensor(0.5)\n",
    "o = tf.convert_to_tensor(-3.0)\n",
    "for _ in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        loss = (o - w * x) ** 2\n",
    "    grad_loss = tape.gradient(loss, x)\n",
    "    x -= 0.1 * grad_loss\n",
    "    print(\"Loss = {:05.2f},  x = {:05.2f} \".format(loss.numpy(), x.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf.Variable\n",
    "\n",
    "Again grad wrt w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 20.25,  w = 00.23 \n",
      "Loss = 13.62,  w = 00.01 \n",
      "Loss = 09.16,  w = -0.17 \n",
      "Loss = 06.16,  w = -0.32 \n",
      "Loss = 04.14,  w = -0.44 \n",
      "Loss = 02.78,  w = -0.54 \n",
      "Loss = 01.87,  w = -0.63 \n",
      "Loss = 01.26,  w = -0.69 \n",
      "Loss = 00.85,  w = -0.75 \n",
      "Loss = 00.57,  w = -0.79 \n",
      "Loss = 00.38,  w = -0.83 \n",
      "Loss = 00.26,  w = -0.86 \n",
      "Loss = 00.17,  w = -0.89 \n",
      "Loss = 00.12,  w = -0.91 \n",
      "Loss = 00.08,  w = -0.92 \n",
      "Loss = 00.05,  w = -0.94 \n",
      "Loss = 00.04,  w = -0.95 \n",
      "Loss = 00.02,  w = -0.96 \n",
      "Loss = 00.02,  w = -0.97 \n",
      "Loss = 00.01,  w = -0.97 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = tf.convert_to_tensor(3.0)\n",
    "# w = tf.Variable(0.5)\n",
    "# o = tf.convert_to_tensor(-3.0)\n",
    "\n",
    "x = tf.constant(3.0)\n",
    "w = tf.Variable(0.5)\n",
    "o = tf.constant(-3.0)\n",
    "for _ in range(20):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        loss = (o - w * x) ** 2\n",
    "    grad_loss = tape.gradient(loss, w)\n",
    "    w.assign_sub(0.01 * grad_loss)\n",
    "    print(\"Loss = {:05.2f},  w = {:05.2f} \".format(loss.numpy(), w.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
