---
title: Gradient Descent and its variants, continue ...
---


## 1402/07/30

* [The Application of Taylor Expansion in Reducing the Size of Convolutional Neural Networks for Classifying Impressionism and Miniature Style Paintings](https://fumcs.github.io/publications/#TaylorExpansion_in_CNN_prunning99) (کاربرد بسط تیلور در کاهش حجم شبکه های عصبی پیچشی برای طبقه بندی نقاشی های سبک امپرسیونیسم و مینیاتور
)

TBA 

## 1402/08
* [Stochastic Gradient Descent](https://www.d2l.ai/chapter_optimization/sgd.html)
* [Minibatch Stochastic Gradient Descent](https://www.d2l.ai/chapter_optimization/minibatch-sgd.html)
* [Momentum](https://www.d2l.ai/chapter_optimization/momentum.html)
* [Visualization of Momentum](https://milania.de/blog/Introduction_to_neural_network_optimizers_%5Bpart_1%5D_%E2%80%93_momentum_optimization)

**Further Reading**{: .label .label-yellow }

* [Matrix Calculus, d2l](https://www.d2l.ai/chapter_preliminaries/calculus.html) 
* [Matrix Derivative in Wiki](https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions)
* [d2l package installation on google colab](https://stackoverflow.com/questions/76248695/d2l-package-installation-on-google-colab)
* [Preliminaries](https://d2l.ai/chapter_preliminaries/index.html)
* [Linear Neural Networks for Regression](https://d2l.ai/chapter_linear-regression/index.html)


* [Fully Connected to Fully Convolutional: Road to Yesterday](https://fumcs.github.io/publications/#FC2FC_2022)(تمام متصل به تمام پیچشی: پلی به گذشته)
