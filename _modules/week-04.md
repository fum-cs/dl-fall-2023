---
title: Gradient Descent and its variants, continue ...
---


## 1402/07/30

* [The Application of Taylor Expansion in Reducing the Size of Convolutional Neural Networks for Classifying Impressionism and Miniature Style Paintings](https://fumcs.github.io/publications/#TaylorExpansion_in_CNN_prunning99) (کاربرد بسط تیلور در کاهش حجم شبکه های عصبی پیچشی برای طبقه بندی نقاشی های سبک امپرسیونیسم و مینیاتور
)

**HW1**{: .label .label-red } [Real Time Sudoku Solver](https://vu.um.ac.ir/mod/assign/view.php?id=454184), due: ~~1402/08/04~~,
The deadline for the assignment submission has been extended to 1402/08/12 with a 10 percent penalty for each day of delay from 08/04. 

**HW2**{: .label .label-red } [Generate Persian Sudoku](https://vu.um.ac.ir/mod/assign/view.php?id=454185), due: ~~1402/08/08~~ Extended until 1402/08/13

**Further Reading**{: .label .label-yellow }
* [Algorithm X](https://mamintoosi.github.io/slides/topics/DLX/DLX.html)



## 1402/08/07

* Momentum 
    - [Momentum](https://www.d2l.ai/chapter_optimization/momentum.html), Until 12.6.1.4

* [Chapter 2: The mathematical building blocks of neural networks](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter02_mathematical-building-blocks.ipynb)

**Further Reading**{: .label .label-yellow }
* Momentum 
    - [Visualization of Momentum](https://milania.de/blog/Introduction_to_neural_network_optimizers_%5Bpart_1%5D_%E2%80%93_momentum_optimization)
    - distill: [Why Momentum Really Works?](https://distill.pub/2017/momentum/)

* [Stochastic Gradient Descent](https://www.d2l.ai/chapter_optimization/sgd.html)
* [Minibatch Stochastic Gradient Descent](https://www.d2l.ai/chapter_optimization/minibatch-sgd.html)
* [Binary Accuracy](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy)

## 1402/08/10

Class Canceled

TBA 

## 1402/08/14

* [Chapter 3: Introduction to Keras and TensorFlow](https://colab.research.google.com/github/fchollet/deep-learning-with-python-notebooks/blob/master/chapter03_introduction-to-keras-and-tf.ipynb)


**Further Reading**{: .label .label-yellow }

* [Matrix Calculus, d2l](https://www.d2l.ai/chapter_preliminaries/calculus.html) 
* [Matrix Derivative in Wiki](https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions)
* [d2l package installation on google colab](https://stackoverflow.com/questions/76248695/d2l-package-installation-on-google-colab)
* [Preliminaries](https://d2l.ai/chapter_preliminaries/index.html)
* [Linear Neural Networks for Regression](https://d2l.ai/chapter_linear-regression/index.html)


* [Fully Connected to Fully Convolutional: Road to Yesterday](https://fumcs.github.io/publications/#FC2FC_2022)(تمام متصل به تمام پیچشی: پلی به گذشته)
